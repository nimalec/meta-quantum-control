Job ID: 286928
Job Account: quantumsensing
Hosts: dgx20
GPU 0: NVIDIA H100 80GB HBM3 (UUID: GPU-7d2c6525-5d54-14c7-ceba-d3fe3850e4b6)
GPU 1: NVIDIA H100 80GB HBM3 (UUID: GPU-8fa9d6fc-1f55-f27c-d348-2fc58690e9b9)
CUDA VISIBLE DEVICES: 0,1
------------
======================================================================
Meta-RL for Quantum Control - Training
======================================================================
Config: ../../configs/experiment_config.yaml

Device: cuda

Target gate: pauli_x

Setting up quantum environment...
QuantumEnvironment initialized: d=2, n_controls=2, T=1.0
  Environment created: {'n_cached_operators': 0, 'n_cached_simulators': 0, 'n_cached_torch_simulators': 0, 'cache_size_mb': 6e-06}

Creating task distribution...
  Task variance σ²_θ = 816750000.2707

Creating policy network...
  Parameters: 184,008
  Lipschitz constant: 0.06

Initializing MAML...
  Inner: 5 steps @ lr=0.01
  Meta lr: 0.001
  Second-order: False

Integration settings:
  dt: 0.01
  method: RK4

Setting up trainer...

Checkpoints will be saved to: checkpoints/maml_best_pauli_x.pt

======================================================================
Starting training...
======================================================================

Starting MAML training for 55 iterations...
Tasks per batch: 32
Inner steps: 5, Inner LR: 0.01
Meta LR: 0.001

Iter 0/55 | Meta Loss: 1.0000 | Task Loss: 1.0000 ± 0.0000 | Range: [1.0000, 1.0000] | Grad Norm: 0.0005
Iter 2/55 | Meta Loss: 0.6075 | Task Loss: 0.6075 ± 0.0007 | Range: [0.6066, 0.6095] | Grad Norm: 2.1924

[Validation] Iter 2
  Pre-adapt loss:  0.1958
  Post-adapt loss: 0.0352
  Val Fidelity: 0.9648 ± 0.0003
  Val Error: 0.0352
  Adaptation gain: 0.1607

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 4/55 | Meta Loss: 0.0213 | Task Loss: 0.0213 ± 0.0015 | Range: [0.0179, 0.0286] | Grad Norm: 0.9446

[Validation] Iter 4
  Pre-adapt loss:  0.4690
  Post-adapt loss: 0.0756
  Val Fidelity: 0.9244 ± 0.0008
  Val Error: 0.0756
  Adaptation gain: 0.3934

Iter 6/55 | Meta Loss: 0.0515 | Task Loss: 0.0515 ± 0.0025 | Range: [0.0505, 0.0604] | Grad Norm: 1.4784

[Validation] Iter 6
  Pre-adapt loss:  0.1191
  Post-adapt loss: 0.0114
  Val Fidelity: 0.9886 ± 0.0027
  Val Error: 0.0114
  Adaptation gain: 0.1077

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 8/55 | Meta Loss: 0.0006 | Task Loss: 0.0006 ± 0.0011 | Range: [0.0003, 0.0051] | Grad Norm: 0.1059

[Validation] Iter 8
  Pre-adapt loss:  0.1252
  Post-adapt loss: 0.0157
  Val Fidelity: 0.9843 ± 0.0013
  Val Error: 0.0157
  Adaptation gain: 0.1095

Iter 10/55 | Meta Loss: 0.0263 | Task Loss: 0.0263 ± 0.0012 | Range: [0.0257, 0.0314] | Grad Norm: 1.0112

[Validation] Iter 10
  Pre-adapt loss:  0.1093
  Post-adapt loss: 0.0135
  Val Fidelity: 0.9865 ± 0.0015
  Val Error: 0.0135
  Adaptation gain: 0.0959

Iter 12/55 | Meta Loss: 0.0017 | Task Loss: 0.0017 ± 0.0006 | Range: [0.0013, 0.0039] | Grad Norm: 0.2457

[Validation] Iter 12
  Pre-adapt loss:  0.0133
  Post-adapt loss: 0.0013
  Val Fidelity: 0.9987 ± 0.0005
  Val Error: 0.0013
  Adaptation gain: 0.0120

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 14/55 | Meta Loss: 0.0077 | Task Loss: 0.0077 ± 0.0008 | Range: [0.0073, 0.0107] | Grad Norm: 0.5704

[Validation] Iter 14
  Pre-adapt loss:  0.1227
  Post-adapt loss: 0.0112
  Val Fidelity: 0.9888 ± 0.0006
  Val Error: 0.0112
  Adaptation gain: 0.1115

Iter 16/55 | Meta Loss: 0.0080 | Task Loss: 0.0080 ± 0.0012 | Range: [0.0076, 0.0129] | Grad Norm: 0.5783

[Validation] Iter 16
  Pre-adapt loss:  0.0266
  Post-adapt loss: 0.0025
  Val Fidelity: 0.9975 ± 0.0009
  Val Error: 0.0025
  Adaptation gain: 0.0241

Iter 18/55 | Meta Loss: 0.0008 | Task Loss: 0.0008 ± 0.0021 | Range: [0.0000, 0.0090] | Grad Norm: 0.0179

[Validation] Iter 18
  Pre-adapt loss:  0.0217
  Post-adapt loss: 0.0022
  Val Fidelity: 0.9978 ± 0.0006
  Val Error: 0.0022
  Adaptation gain: 0.0195

Iter 20/55 | Meta Loss: 0.0056 | Task Loss: 0.0056 ± 0.0006 | Range: [0.0045, 0.0078] | Grad Norm: 0.4744

[Validation] Iter 20
  Pre-adapt loss:  0.0590
  Post-adapt loss: 0.0066
  Val Fidelity: 0.9934 ± 0.0019
  Val Error: 0.0066
  Adaptation gain: 0.0524

Iter 22/55 | Meta Loss: 0.0039 | Task Loss: 0.0039 ± 0.0017 | Range: [0.0031, 0.0123] | Grad Norm: 0.3708

[Validation] Iter 22
  Pre-adapt loss:  0.0074
  Post-adapt loss: 0.0009
  Val Fidelity: 0.9991 ± 0.0011
  Val Error: 0.0009
  Adaptation gain: 0.0065

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 24/55 | Meta Loss: 0.0004 | Task Loss: 0.0004 ± 0.0011 | Range: [0.0001, 0.0062] | Grad Norm: 0.0593

[Validation] Iter 24
  Pre-adapt loss:  0.0166
  Post-adapt loss: 0.0015
  Val Fidelity: 0.9985 ± 0.0002
  Val Error: 0.0015
  Adaptation gain: 0.0151

Iter 26/55 | Meta Loss: 0.0029 | Task Loss: 0.0029 ± 0.0009 | Range: [0.0025, 0.0073] | Grad Norm: 0.3440

[Validation] Iter 26
  Pre-adapt loss:  0.0344
  Post-adapt loss: 0.0032
  Val Fidelity: 0.9968 ± 0.0010
  Val Error: 0.0032
  Adaptation gain: 0.0312

Iter 28/55 | Meta Loss: 0.0018 | Task Loss: 0.0018 ± 0.0006 | Range: [0.0014, 0.0044] | Grad Norm: 0.2577

[Validation] Iter 28
  Pre-adapt loss:  0.0040
  Post-adapt loss: 0.0009
  Val Fidelity: 0.9991 ± 0.0017
  Val Error: 0.0009
  Adaptation gain: 0.0031

Iter 30/55 | Meta Loss: 0.0004 | Task Loss: 0.0004 ± 0.0007 | Range: [0.0001, 0.0024] | Grad Norm: 0.0553

[Validation] Iter 30
  Pre-adapt loss:  0.0100
  Post-adapt loss: 0.0014
  Val Fidelity: 0.9986 ± 0.0012
  Val Error: 0.0014
  Adaptation gain: 0.0087

Iter 32/55 | Meta Loss: 0.0021 | Task Loss: 0.0021 ± 0.0012 | Range: [0.0016, 0.0065] | Grad Norm: 0.2631

[Validation] Iter 32
  Pre-adapt loss:  0.0175
  Post-adapt loss: 0.0020
  Val Fidelity: 0.9980 ± 0.0012
  Val Error: 0.0020
  Adaptation gain: 0.0155

Iter 34/55 | Meta Loss: 0.0014 | Task Loss: 0.0014 ± 0.0018 | Range: [0.0007, 0.0099] | Grad Norm: 0.1800

[Validation] Iter 34
  Pre-adapt loss:  0.0015
  Post-adapt loss: 0.0004
  Val Fidelity: 0.9996 ± 0.0007
  Val Error: 0.0004
  Adaptation gain: 0.0010

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 36/55 | Meta Loss: 0.0004 | Task Loss: 0.0004 ± 0.0006 | Range: [0.0001, 0.0020] | Grad Norm: 0.0596

[Validation] Iter 36
  Pre-adapt loss:  0.0067
  Post-adapt loss: 0.0007
  Val Fidelity: 0.9993 ± 0.0007
  Val Error: 0.0007
  Adaptation gain: 0.0060

Iter 38/55 | Meta Loss: 0.0010 | Task Loss: 0.0010 ± 0.0006 | Range: [0.0009, 0.0045] | Grad Norm: 0.1964

[Validation] Iter 38
  Pre-adapt loss:  0.0099
  Post-adapt loss: 0.0014
  Val Fidelity: 0.9986 ± 0.0018
  Val Error: 0.0014
  Adaptation gain: 0.0085

Iter 40/55 | Meta Loss: 0.0006 | Task Loss: 0.0006 ± 0.0010 | Range: [0.0003, 0.0046] | Grad Norm: 0.1183
  [DIAGNOSTIC] 2/8 parameters have zero/no gradients

[Validation] Iter 40
  Pre-adapt loss:  0.0003
  Post-adapt loss: 0.0001
  Val Fidelity: 0.9999 ± 0.0002
  Val Error: 0.0001
  Adaptation gain: 0.0002

Checkpoint saved to checkpoints/maml_best_pauli_x_best.pt
Policy weights saved to checkpoints/maml_best_pauli_x_best_policy.pt
Iter 42/55 | Meta Loss: 0.0004 | Task Loss: 0.0004 ± 0.0008 | Range: [0.0001, 0.0031] | Grad Norm: 0.0629

[Validation] Iter 42
  Pre-adapt loss:  0.0047
  Post-adapt loss: 0.0007
  Val Fidelity: 0.9993 ± 0.0008
  Val Error: 0.0007
  Adaptation gain: 0.0040

Iter 44/55 | Meta Loss: 0.0007 | Task Loss: 0.0007 ± 0.0005 | Range: [0.0005, 0.0027] | Grad Norm: 0.1495

[Validation] Iter 44
  Pre-adapt loss:  0.0044
  Post-adapt loss: 0.0005
  Val Fidelity: 0.9995 ± 0.0003
  Val Error: 0.0005
  Adaptation gain: 0.0039

Iter 46/55 | Meta Loss: 0.0003 | Task Loss: 0.0003 ± 0.0004 | Range: [0.0001, 0.0018] | Grad Norm: 0.0670

[Validation] Iter 46
  Pre-adapt loss:  0.0008
  Post-adapt loss: 0.0008
  Val Fidelity: 0.9992 ± 0.0019
  Val Error: 0.0008
  Adaptation gain: 0.0000

Iter 48/55 | Meta Loss: 0.0003 | Task Loss: 0.0003 ± 0.0007 | Range: [0.0001, 0.0034] | Grad Norm: 0.0693

[Validation] Iter 48
  Pre-adapt loss:  0.0036
  Post-adapt loss: 0.0007
  Val Fidelity: 0.9993 ± 0.0009
  Val Error: 0.0007
  Adaptation gain: 0.0029

Iter 50/55 | Meta Loss: 0.0005 | Task Loss: 0.0005 ± 0.0006 | Range: [0.0003, 0.0033] | Grad Norm: 0.1083

[Validation] Iter 50
  Pre-adapt loss:  0.0019
  Post-adapt loss: 0.0004
  Val Fidelity: 0.9996 ± 0.0006
  Val Error: 0.0004
  Adaptation gain: 0.0015

Iter 52/55 | Meta Loss: 0.0005 | Task Loss: 0.0005 ± 0.0012 | Range: [0.0000, 0.0048] | Grad Norm: 0.0261

[Validation] Iter 52
  Pre-adapt loss:  0.0006
  Post-adapt loss: 0.0004
  Val Fidelity: 0.9996 ± 0.0010
  Val Error: 0.0004
  Adaptation gain: 0.0002

Iter 54/55 | Meta Loss: 0.0004 | Task Loss: 0.0004 ± 0.0008 | Range: [0.0001, 0.0044] | Grad Norm: 0.0701

[Validation] Iter 54
  Pre-adapt loss:  0.0023
  Post-adapt loss: 0.0005
  Val Fidelity: 0.9995 ± 0.0010
  Val Error: 0.0005
  Adaptation gain: 0.0018

Checkpoint saved to checkpoints/maml_best_pauli_x.pt
Policy weights saved to checkpoints/maml_best_pauli_x_policy.pt
Training history saved to: checkpoints/training_history.json

Training complete!

======================================================================
Training complete!
======================================================================

Final model saved to: checkpoints/maml_best_pauli_x.pt
Best model saved to: checkpoints/maml_best_pauli_x_best.pt

Cache stats: {'n_cached_operators': 0, 'n_cached_simulators': 0, 'n_cached_torch_simulators': 2624, 'cache_size_mb': 0.242969}
Job completed.
