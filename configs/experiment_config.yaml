# Meta-RL for Quantum Control - Experiment Configuration

# Random seed
seed: 42

# Quantum System
psd_model: 'one_over_f'  # 'one_over_f', 'lorentzian', 'double_exp' (used if model_types not specified)
horizon: 1.0  # Total evolution time (arbitrary units)
target_gate: 'pauli_x'  # 'hadamard', 'pauli_x', 'pauli_y'

# Task Distribution
task_dist_type: 'uniform'

alpha_range: [0.5, 2.0]      # Spectral exponent range
A_range: [0.001, 0.01]         # FIXED: Increased to [0.01, 0.1] for better task diversity and meta-learning
omega_c_range: [100, 1000]    # Cutoff frequency range

# NEW: Mixed Model Sampling (comment out for single model mode)
# Uncomment to enable mixed model sampling across different PSD types
# model_types: ['one_over_f', 'lorentzian']  # List of model types to sample
# model_probs: [0.5, 0.5]  # Probabilities (must sum to 1.0). If omitted, uniform distribution

# Policy Network
task_feature_dim: 4  # NEW: Changed from 3 to 4 to include model_type encoding
hidden_dim: 64
n_hidden_layers: 1
n_segments: 20
n_controls: 2
output_scale: 2.0  # FIXED: Increased from 1.0 to allow stronger control signals for better gate fidelity
activation: 'tanh'

# MAML Hyperparameters
inner_lr: 0.02  # FIXED: Further reduced from 0.005 for stable gradients with differentiable simulator
inner_steps: 10   # FIXED: Increased from 3 to allow sufficient adaptation (meta-learning needs this!)
meta_lr: 0.02 
first_order: true  # FIXED: Use FOMAML initially to avoid complex eigenvalue gradient issues

# Training
n_iterations: 60
tasks_per_batch: 10  # FIXED: Increased from 4 for more stable meta-gradient estimates
n_support: 2
n_query: 2
log_interval: 2
val_interval: 2
val_tasks: 5

# Checkpointing
save_dir: 'checkpoints'

# Robust Baseline (for comparison)
robust_type: 'minimax'  # 'average', 'minimax', 'cvar'
robust_iterations: 1000
robust_tasks_per_batch: 16

# Optimality Gap Experiments
gap_n_samples: 100
gap_K_values: [1, 3, 5, 10, 20]
gap_variance_range: [0.01, 0.05, 0.1, 0.2, 0.5]
